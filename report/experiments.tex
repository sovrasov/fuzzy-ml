\section{Результаты экспериментов}
Для того, чтобы убедиться, что программная реализация обучения модели работает
корректно, были проведены её запуски в различных режимах.
В режиме <<oneshot>> были построены модели с различным количеством кластеров (\(NC\)) и
частиц в рое (\(NP\)). Чем больше кластеров, тем больше правил в модели, т.е. она становится сложнее,
а значит и более склонна к переобучению. С увеличением числа частиц растёт интенсивность
подгонки параметров модели под обучающую выборку, что также может привести к переобучению.
Резуьтаты экспериментов приведены в таблице \ref{table:oneshot}. Во всех экспериментах объём
тестовой выборки равен трети от объёма всех данных. В каждой ячейке таблицы указана
доля верных ответов классификатора в процентах до и после этапа параметрической оптимизации.
  \begin{table}[h]
    \begin{tabular}{| l | l | l | l | l |}
      \hline
    Выборка & NP=20 NC=10 & NP=50 NC=10  & NP=25 NC=20 & NP=100 NC=20 \\ \hline
    Обучающая & 90,4 / 95,2 & 90,4 / 98 & 93,3 / 99 & 93,3 / 99 \\ \hline
    Тестовая  & 95,5 / 91,1 & 95,5 / 93,3  & 95,5 / 91,1  & 95,5 / 93,3 \\ \hline
    \end{tabular}
    \caption{Результаты работы модели в режиме <<oneshot>>}
    \label{table:oneshot}
  \end{table}
\par
Как видно из таблицы \ref{table:oneshot}, оптимизация в большинстве случаев улучшает
результат на обучающей выборке и ухудшает на тестовой, происходит переобучение.
В рассматриваемой задаче входные данные не настолько сложные, чтобы дополнительно подстраивать
модель после структурной идентификации. Это имеет смысл делать, только при получении
плохих результатов после идентификации.
\par
Аналогичные эксперименты были проведены и в режиме <<crossv>> при числе разбиений, равном 5.
Их результаты приведены в таблице \ref{table:crossv}. Дисперсия результатов оценки качества
моделей, построенных при перекрёстном контроле, довольно большая, что объясняется
недостаточным для получения устойчивых статистических характеристик объёмом входных данных.
При рассматриваемых параметрах только в одном случае среднее качество классификации
оказалось ниже, чем 92\%. Чтобы подобрать более оптимальные параметры алгоритмов
струкрурной идентификации и роя частиц, можно провести гиперпараметрическую оптимизацию,
используя в роли критерия значение качества, получаемое скользящим контролем, но
подобные эксперименты выходят за рамки данной лабораторной работы.
  \begin{table}[h]
    \begin{tabular}{| l | l | l | l | l |}
      \hline
      & NP=20 NC=10 & NP=50 NC=10  & NP=25 NC=20 & NP=100 NC=20 \\ \hline
    Среднее качество & 92,6  & 93,3 & 90,6 & 93,3 \\ \hline
    Дисперсия        & 7,1   &  6,9 &  5,7 &  2,1 \\ \hline
    \end{tabular}
    \caption{Результаты работы модели в режиме <<crossv>>}
    \label{table:crossv}
  \end{table}
\newpage
